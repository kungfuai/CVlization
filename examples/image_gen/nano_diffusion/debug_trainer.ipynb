{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the behavior of diffuser Trainer and train5\n",
    "\n",
    "- Create a shared dataloader\n",
    "- Create the same model\n",
    "- Seed everything\n",
    "- Compare the model weights\n",
    "- Train for one step\n",
    "- Check the loss\n",
    "- Compare the model weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 21:11:15.993201: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-09 21:11:16.036015: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-10-09 21:11:18,092 - datasets - INFO - PyTorch version 2.0.1 available. (config.py:54)\n",
      "2024-10-09 21:11:18,093 - datasets - INFO - TensorFlow version 2.13.1 available. (config.py:101)\n",
      "2024-10-09 21:11:18,094 - datasets - INFO - JAX version 0.4.14 available. (config.py:114)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n",
    "\n",
    "from examples.image_gen.nano_diffusion.train5 import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# use deterministic algorithms\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 113.67 M\n"
     ]
    }
   ],
   "source": [
    "from examples.image_gen.nano_diffusion.train5 import create_model\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "# seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "denoising_model = create_model().to(device)\n",
    "\n",
    "optimizer = optim.AdamW(denoising_model.parameters(), lr=1e-4)\n",
    "lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda step: 1)\n",
    "\n",
    "num_timesteps = 1000\n",
    "betas = torch.linspace(1e-4, 0.02, num_timesteps)\n",
    "alphas = 1 - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "noise_schedule = {\n",
    "    \"betas\": betas.to(device),\n",
    "    \"alphas\": alphas.to(device),\n",
    "    \"alphas_cumprod\": alphas_cumprod.to(device),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 0: -0.0009031191002577543\n",
      "Parameter 1: -0.03329317271709442\n",
      "Parameter 2: 0.00011141580034745857\n",
      "Parameter 3: -0.006176298949867487\n",
      "Parameter 4: 1.8592058040667325e-05\n",
      "Parameter 5: 0.0011070019099861383\n",
      "Parameter 6: 1.0\n",
      "Parameter 7: 0.0\n",
      "Parameter 8: 6.0346192185534164e-05\n",
      "Parameter 9: 0.002473791129887104\n",
      "Parameter 10: -7.468119292752817e-06\n",
      "Parameter 11: -0.004966080188751221\n"
     ]
    }
   ],
   "source": [
    "def print_params(model):\n",
    "    for i, w in enumerate(model.parameters()):\n",
    "        print(f\"Parameter {i}: {w.data.mean()}\")\n",
    "        if i > 10:\n",
    "            break\n",
    "\n",
    "\n",
    "print_params(denoising_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current seed: 0\n",
      "noise.mean(): tensor(-0.0030, device='cuda:0') shape: torch.Size([32, 3, 32, 32])\n",
      "t: tensor(532.7188, device='cuda:0')\n",
      "Step 0/1, Examples trained: 32, Train Loss: 1.0660, LR: 0.000100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up a one-step train loop\n",
    "# seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "train_loop(\n",
    "    denoising_model=denoising_model,\n",
    "    train_dataloader=dataloader,\n",
    "    val_dataloader=None,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    noise_schedule=noise_schedule,\n",
    "    n_T=num_timesteps,\n",
    "    total_steps=1,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = denoising_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 0: -0.0009030032088048756\n",
      "Parameter 1: -0.033293142914772034\n",
      "Parameter 2: 0.00011159940186189488\n",
      "Parameter 3: -0.006176290102303028\n",
      "Parameter 4: 1.8253314920002595e-05\n",
      "Parameter 5: 0.001105814822949469\n",
      "Parameter 6: 1.000002145767212\n",
      "Parameter 7: 1.0934378224192187e-05\n",
      "Parameter 8: 5.899346433579922e-05\n",
      "Parameter 9: 0.002464410848915577\n",
      "Parameter 10: -7.634651410626248e-06\n",
      "Parameter 11: -0.004975453019142151\n"
     ]
    }
   ],
   "source": [
    "print_params(denoising_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 113.67 M\n",
      "Parameter 0: -0.0009031191002577543\n",
      "Parameter 1: -0.03329317271709442\n",
      "Parameter 2: 0.00011141580034745857\n",
      "Parameter 3: -0.006176298949867487\n",
      "Parameter 4: 1.8592058040667325e-05\n",
      "Parameter 5: 0.0011070019099861383\n",
      "Parameter 6: 1.0\n",
      "Parameter 7: 0.0\n",
      "Parameter 8: 6.0346192185534164e-05\n",
      "Parameter 9: 0.002473791129887104\n",
      "Parameter 10: -7.468119292752817e-06\n",
      "Parameter 11: -0.004966080188751221\n"
     ]
    }
   ],
   "source": [
    "denoising_model2 = create_model().to(device)\n",
    "print_params(denoising_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 21:11:42,461 - cvlization.torch.training_pipeline.image_gen.diffuser_unconditional.pipeline - INFO - ***** Running training ***** (pipeline.py:73)\n",
      "2024-10-09 21:11:42,462 - cvlization.torch.training_pipeline.image_gen.diffuser_unconditional.pipeline - INFO -   Num Epochs = 1 (pipeline.py:75)\n",
      "2024-10-09 21:11:42,462 - cvlization.torch.training_pipeline.image_gen.diffuser_unconditional.pipeline - INFO -   Instantaneous batch size per device = 32 (pipeline.py:76)\n",
      "2024-10-09 21:11:42,462 - cvlization.torch.training_pipeline.image_gen.diffuser_unconditional.pipeline - INFO -   Total train batch size (w. parallel, distributed & accumulation) = 32 (pipeline.py:77)\n",
      "2024-10-09 21:11:42,462 - cvlization.torch.training_pipeline.image_gen.diffuser_unconditional.pipeline - INFO -   Gradient Accumulation steps = 1 (pipeline.py:78)\n",
      "2024-10-09 21:11:42,463 - cvlization.torch.training_pipeline.image_gen.diffuser_unconditional.pipeline - INFO -   Total optimization steps = 1 (pipeline.py:79)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd3cfa9ea464139b32fa1288e2cc05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise.mean(): tensor(-0.0030, device='cuda:0') shape: torch.Size([32, 3, 32, 32])\n",
      "timesteps: tensor(532.7188, device='cuda:0')\n",
      "loss: 1.0660488605499268 lr: 0.0001 step: 1\n",
      "Parameter 0: -0.0009030032088048756\n",
      "Parameter 1: -0.033293142914772034\n",
      "Parameter 2: 0.00011159940186189488\n",
      "Parameter 3: -0.006176290102303028\n",
      "Parameter 4: 1.8253314920002595e-05\n",
      "Parameter 5: 0.001105814822949469\n",
      "Parameter 6: 1.000002145767212\n",
      "Parameter 7: 1.0934378224192187e-05\n",
      "Parameter 8: 5.899346433579922e-05\n",
      "Parameter 9: 0.002464410848915577\n",
      "Parameter 10: -7.634651410626248e-06\n",
      "Parameter 11: -0.004975453019142151\n"
     ]
    }
   ],
   "source": [
    "# train with diffuser trainer\n",
    "import random\n",
    "from cvlization.torch.training_pipeline.image_gen.diffuser_unconditional.pipeline import TrainingPipeline, Trainer, DDPMScheduler, Accelerator, ProjectConfiguration\n",
    "\n",
    "\n",
    "class AdaptedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        return {\n",
    "            \"input\": img,\n",
    "            \"target\": label,\n",
    "        }\n",
    "\n",
    "adapted_dataset = AdaptedDataset(dataset)\n",
    "adapted_dataloader = DataLoader(adapted_dataset, batch_size=32, shuffle=False)\n",
    "optimizer2 = optim.AdamW(denoising_model2.parameters(), lr=1e-4)\n",
    "lr_scheduler2 = optim.lr_scheduler.LambdaLR(optimizer2, lr_lambda=lambda step: 1)\n",
    "\n",
    "ddpm_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_timesteps,\n",
    "    beta_schedule=\"linear\",\n",
    "    prediction_type=\"epsilon\",\n",
    ")\n",
    "accelerator_project_config = ProjectConfiguration(total_limit=1)\n",
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=1,\n",
    "    mixed_precision=None,\n",
    "    log_with=None,\n",
    "    project_dir=None,\n",
    "    project_config=accelerator_project_config,\n",
    ")\n",
    "accelerator = None\n",
    "denoising_model2.train()\n",
    "if accelerator is not None:\n",
    "    denoising_model2, optimizer2, adapted_dataloader, lr_scheduler2 = accelerator.prepare(\n",
    "        denoising_model2, optimizer2, adapted_dataloader, lr_scheduler2\n",
    "    )\n",
    "trainer = Trainer(\n",
    "    model=denoising_model2,\n",
    "    accelerator=accelerator,\n",
    "    output_dir=\"data/tensorboard\",\n",
    "    noise_scheduler=ddpm_scheduler,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optimizer=optimizer2,\n",
    "    lr_scheduler=lr_scheduler2,\n",
    "    logger=None,\n",
    "    use_ema=False,\n",
    "    train_batch_size=32,\n",
    "    ddpm_num_inference_steps=num_timesteps,\n",
    "    num_epochs=1,\n",
    "    prediction_type=\"epsilon\",\n",
    "    num_update_steps_per_epoch=1,\n",
    "    max_train_steps=1,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "trainer.train(train_dataloader=adapted_dataloader)\n",
    "if accelerator is not None:\n",
    "    denoising_model2 = accelerator.unwrap_model(denoising_model2)\n",
    "denoising_model2.eval()\n",
    "\n",
    "print_params(denoising_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1218)\n",
      "tensor(-0.1218)\n"
     ]
    }
   ],
   "source": [
    "# compare the two dataloaders\n",
    "first_batch1 = next(iter(dataloader))\n",
    "first_batch2 = next(iter(adapted_dataloader))\n",
    "print(first_batch1[0].mean())\n",
    "print(first_batch2[\"input\"].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(-0.0025, device='cuda:0')\n",
      "tensor(-0.0046, device='cuda:0')\n",
      "0\n",
      "tensor(-0.0025, device='cuda:0')\n",
      "tensor(-0.0046, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "print(torch.initial_seed())\n",
    "# print(torch.seed())\n",
    "print(torch.randn((32, 3, 32, 32)).to(device).mean())\n",
    "print(torch.randn((32, 3, 32, 32)).to(device).mean())\n",
    "torch.manual_seed(0)\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "print(torch.initial_seed())\n",
    "# print(torch.seed())\n",
    "print(torch.randn((32, 3, 32, 32)).to(device).mean())\n",
    "print(torch.randn((32, 3, 32, 32)).to(device).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
