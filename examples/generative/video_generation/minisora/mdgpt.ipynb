{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 14:11:57.653439: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 14:11:58.274313: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-12/lib64\n",
      "2024-03-25 14:11:58.274365: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-12/lib64\n",
      "2024-03-25 14:11:58.274370: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/zzsi/miniconda2/envs/cv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from cvlization.torch.training_pipeline.lm.mdgpt import MDGPTTrainingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens per iteration will be: 32,768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzsi/miniconda2/envs/cv/lib/python3.8/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "pipe = MDGPTTrainingPipeline(config=MDGPTTrainingPipeline.Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8, 64, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"flying_mnist_tokens_32frames_train.npy\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.train_data = data.reshape(1000, -1).astype(np.int64)\n",
    "pipe.val_data = pipe.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.reshape(1000, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 64, 64, 3)\n",
      "data shape: (1000, 32768)\n",
      "positions shape: (32768, 3)\n"
     ]
    }
   ],
   "source": [
    "meshgrid_args = [np.arange(s) for s in data.shape[1:]]\n",
    "positions = np.array(\n",
    "                np.meshgrid(\n",
    "                    *meshgrid_args,\n",
    "                    indexing=\"ij\"\n",
    "                ),\n",
    "            ).transpose(1, 2, 3, 0)\n",
    "\n",
    "print(positions.shape)\n",
    "\n",
    "positions = positions.reshape(-1, positions.shape[-1])\n",
    "print(f\"data shape: {data2.shape}\")\n",
    "print(f\"positions shape: {positions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0],\n",
       "       [ 0,  0,  1],\n",
       "       [ 0,  0,  2],\n",
       "       ...,\n",
       "       [ 7, 63, 61],\n",
       "       [ 7, 63, 62],\n",
       "       [ 7, 63, 63]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "end_irow = torch.randint(data2.shape[0], (8,))\n",
    "end_ix = torch.randint(data2.shape[1], (8,))\n",
    "end_ix\n",
    "block_size = 64 * 64 * 3\n",
    "start_ix = end_ix - block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_TOKEN = 5122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ix\n",
    "dst_arr = np.ones((len(start_ix), block_size), dtype=np.int64) * IGNORE_TOKEN\n",
    "for i in range(len(start_ix)):\n",
    "    src_start = max(0, start_ix[i])\n",
    "    src_end = end_ix[i]\n",
    "    dst_start = max(0, -start_ix[i])\n",
    "    dst_end = block_size\n",
    "    # print(i, end_irow[i], src_start, src_end, dst_start, dst_end)\n",
    "    dst_arr[i, dst_start:dst_end] = data2[end_irow[i], src_start:src_end]\n",
    "dst_arr\n",
    "x = dst_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 12288]),\n",
       " tensor([[5122, 5122, 5122,  ..., 4770, 4770, 4770],\n",
       "         [4770, 4770, 4770,  ..., 4770, 4770, 4770],\n",
       "         [4770, 4770, 4770,  ..., 4770, 4770, 4770],\n",
       "         ...,\n",
       "         [4770, 4770, 4770,  ..., 4770, 4770, 4770],\n",
       "         [2352, 2352, 2352,  ..., 4770, 4770, 4770],\n",
       "         [4770, 4770, 4770,  ..., 4770, 4770, 4770]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos = np.ones((len(start_ix), block_size, 3), dtype=np.int64) * 0\n",
    "for i, (s, e) in enumerate(zip(start_ix, end_ix)):\n",
    "    src_start = max(0, s)\n",
    "    src_end = e\n",
    "    dst_start = max(0, -s)\n",
    "    dst_end = block_size\n",
    "    x_pos[i, dst_start:dst_end, :] = positions[src_start:src_end, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 12288, 3]),\n",
       " tensor([[[ 0,  0,  0],\n",
       "          [ 0,  0,  0],\n",
       "          [ 0,  0,  0],\n",
       "          ...,\n",
       "          [ 1, 29, 47],\n",
       "          [ 1, 29, 48],\n",
       "          [ 1, 29, 49]],\n",
       " \n",
       "         [[ 4,  1, 18],\n",
       "          [ 4,  1, 19],\n",
       "          [ 4,  1, 20],\n",
       "          ...,\n",
       "          [ 7,  1, 15],\n",
       "          [ 7,  1, 16],\n",
       "          [ 7,  1, 17]],\n",
       " \n",
       "         [[ 3, 17, 20],\n",
       "          [ 3, 17, 21],\n",
       "          [ 3, 17, 22],\n",
       "          ...,\n",
       "          [ 6, 17, 17],\n",
       "          [ 6, 17, 18],\n",
       "          [ 6, 17, 19]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 2,  6,  6],\n",
       "          [ 2,  6,  7],\n",
       "          [ 2,  6,  8],\n",
       "          ...,\n",
       "          [ 5,  6,  3],\n",
       "          [ 5,  6,  4],\n",
       "          [ 5,  6,  5]],\n",
       " \n",
       "         [[ 0, 38, 54],\n",
       "          [ 0, 38, 55],\n",
       "          [ 0, 38, 56],\n",
       "          ...,\n",
       "          [ 3, 38, 51],\n",
       "          [ 3, 38, 52],\n",
       "          [ 3, 38, 53]],\n",
       " \n",
       "         [[ 1, 53, 26],\n",
       "          [ 1, 53, 27],\n",
       "          [ 1, 53, 28],\n",
       "          ...,\n",
       "          [ 4, 53, 23],\n",
       "          [ 4, 53, 24],\n",
       "          [ 4, 53, 25]]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pos.shape, x_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4770],\n",
       "        [4770],\n",
       "        [4741],\n",
       "        [4770],\n",
       "        [4770],\n",
       "        [4770],\n",
       "        [4770],\n",
       "        [4770]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.stack(\n",
    "    [\n",
    "        torch.from_numpy((\n",
    "            data2[end_irow[i], [e]]\n",
    "        ).astype(np.int64))\n",
    "        for i, e in enumerate(end_ix)\n",
    "    ]\n",
    ")\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 12288, 3)\n",
      "(8, 12288)\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "y_pos = torch.stack(\n",
    "    [\n",
    "        torch.from_numpy((\n",
    "            positions[[e]]\n",
    "        ).astype(np.int64))\n",
    "        for e in end_ix\n",
    "    ]\n",
    ").squeeze(1)\n",
    "print(x_pos.shape)\n",
    "print(x.shape)\n",
    "print(y_pos.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 29, 50],\n",
       "        [ 7,  1, 18],\n",
       "        [ 6, 17, 20],\n",
       "        [ 3, 33,  8],\n",
       "        [ 3,  4,  9],\n",
       "        [ 5,  6,  6],\n",
       "        [ 3, 38, 54],\n",
       "        [ 4, 53, 26]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(x) if not isinstance(x, torch.Tensor) else x\n",
    "x_pos = torch.from_numpy(x_pos) if not isinstance(x_pos, torch.Tensor) else x_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug the forward() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3]), torch.Size([8, 12288, 3]), torch.Size([8, 12288, 3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "idx_to_ignore = (x == IGNORE_TOKEN)\n",
    "#  to the loss function to ignore these tokens\n",
    "relative_pos = y_pos.unsqueeze(1) - x_pos\n",
    "euclidean_dist = torch.norm(relative_pos.float(), dim=-1, keepdim=False)\n",
    "euclidean_dist_exp = torch.exp(-euclidean_dist)\n",
    "y_pos.shape, x_pos.shape, relative_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1, 29, 47],\n",
       "         [ 1, 29, 48],\n",
       "         [ 1, 29, 49]]),\n",
       " tensor([ 1, 29, 50]),\n",
       " tensor([[0, 0, 3],\n",
       "         [0, 0, 2],\n",
       "         [0, 0, 1]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pos[0][-3:, :], y_pos[0], relative_pos[0][-3:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.8239e-26, 7.8239e-26, 7.8239e-26,  ..., 4.9787e-02, 1.3534e-01,\n",
       "        3.6788e-01])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_dist_exp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_dist_exp[euclidean_dist_exp < 1e-6] = 0\n",
    "euclidean_dist_exp += torch.rand_like(euclidean_dist_exp) * 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 12288]), torch.Size([8, 12288]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_ignore.shape, euclidean_dist_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 12288, 3]), torch.Size([8, 12288]), torch.Size([8, 12288]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_dist_exp[idx_to_ignore] = -1\n",
    "sorted_idx = torch.argsort(euclidean_dist_exp, dim=1, descending=True)\n",
    "x_pos.shape, x.shape, sorted_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = 5122\n",
    "x_reordered = torch.gather(x, 1, sorted_idx)\n",
    "x_pos_reordered = torch.gather(x_pos, 1, sorted_idx.unsqueeze(-1).expand(-1, -1, x_pos.shape[-1]))\n",
    "relative_pos_reordered = torch.gather(relative_pos, 1, sorted_idx.unsqueeze(-1).expand(-1, -1, relative_pos.shape[-1]))\n",
    "# re-order\n",
    "x_reordered = torch.cat([torch.ones_like(x_reordered[:, :1]) * START_TOKEN, x_reordered], dim=1)\n",
    "x_pos_reordered = torch.cat([torch.zeros_like(x_pos_reordered[:, :1]), x_pos_reordered], dim=1)\n",
    "relative_pos_reordered = torch.cat([torch.zeros_like(relative_pos_reordered[:, :1]), relative_pos_reordered], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 29, 50]),\n",
       " tensor([[ 0,  0,  0],\n",
       "         [ 1, 29, 49],\n",
       "         [ 0, 29, 50],\n",
       "         [ 1, 28, 50],\n",
       "         [ 1, 28, 49]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pos[0], x_pos_reordered[0][:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune\n",
    "sparse_block_size = 120\n",
    "x_pruned = x_reordered[:, : sparse_block_size]\n",
    "x_pos_pruned = x_pos_reordered[:, : sparse_block_size]\n",
    "relative_pos_pruned = relative_pos_reordered[:, : sparse_block_size]\n",
    "idx_to_ignore = idx_to_ignore[:, : sparse_block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0],\n",
       "         [0, 0, 1],\n",
       "         [1, 0, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 1, 1]]),\n",
       " tensor([[ 0,  0,  0],\n",
       "         [ 1, 29, 49],\n",
       "         [ 0, 29, 50],\n",
       "         [ 1, 28, 50],\n",
       "         [ 1, 28, 49]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx_to_ignore\n",
    "relative_pos_pruned[0][:5, :], x_pos_pruned[0][:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing a new model from scratch\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "number of parameters: 89.00M\n",
      "MDGPT(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(5140, 768)\n",
      "    (wpe): ModuleList(\n",
      "      (0): Embedding(17, 768)\n",
      "      (1): Embedding(129, 768)\n",
      "      (2): Embedding(129, 768)\n",
      "    )\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate=none)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=5140, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "pipe.position_shape = data.shape[1:]\n",
    "model = pipe.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1]) torch.Size([1, 1, 3]) torch.Size([1, 3])\n",
      "relative_pos shape: torch.Size([1, 1, 3])\n",
      "position_shape: (8, 64, 64)\n",
      "d=0, offset=8, relative_pos_pruned shape: torch.Size([1, 2, 3])\n",
      "embedding model: Embedding(17, 768)\n",
      "input to embedding: tensor([[8, 8]])\n",
      "d=1, offset=64, relative_pos_pruned shape: torch.Size([1, 2, 3])\n",
      "embedding model: Embedding(129, 768)\n",
      "input to embedding: tensor([[64, 64]])\n",
      "d=2, offset=64, relative_pos_pruned shape: torch.Size([1, 2, 3])\n",
      "embedding model: Embedding(129, 768)\n",
      "input to embedding: tensor([[64, 65]])\n",
      "after linear, x shape: torch.Size([1, 2, 768])\n"
     ]
    }
   ],
   "source": [
    "cond_x = torch.tensor([[5121]])\n",
    "cond_x_pos = torch.tensor([[[0, 0, 0]]])\n",
    "cond_y_pos = torch.tensor([[0, 0, 1]])\n",
    "print(cond_x.shape, cond_x_pos.shape, cond_y_pos.shape)\n",
    "pipe.model.to(\"cpu\")\n",
    "logits, _ = pipe.model(x_pos=cond_x_pos, x=cond_x, y_pos=cond_y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative_pos shape: torch.Size([2, 1, 3])\n",
      "position_shape: (8, 64, 64)\n",
      "d=0, offset=8, relative_pos_pruned shape: torch.Size([2, 2, 3])\n",
      "embedding model: Embedding(17, 768)\n",
      "input to embedding: tensor([[8, 8],\n",
      "        [8, 8]])\n",
      "d=1, offset=64, relative_pos_pruned shape: torch.Size([2, 2, 3])\n",
      "embedding model: Embedding(129, 768)\n",
      "input to embedding: tensor([[64, 64],\n",
      "        [64, 64]])\n",
      "d=2, offset=64, relative_pos_pruned shape: torch.Size([2, 2, 3])\n",
      "embedding model: Embedding(129, 768)\n",
      "input to embedding: tensor([[64, 65],\n",
      "        [64, 65]])\n",
      "after linear, x shape: torch.Size([2, 2, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5121, 4234],\n",
       "        [5121, 4624]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.generate(\n",
    "    # repeat along the first axis\n",
    "    cond_x_pos.repeat(2, 1, 1),\n",
    "    cond_x.repeat(2, 1),\n",
    "    cond_y_pos.repeat(2, 1).unsqueeze(1),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
