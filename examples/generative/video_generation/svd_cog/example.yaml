name: svd-cog
capability: generative/video_generation
modalities: [vision]
datasets: []
stability: stable
resources:
  gpu: 1
  vram_gb: 24
  disk_gb: 40
presets: [build, predict]
tags: [svd, stable-video-diffusion, image-to-video, cog, pytorch]
tasks: [image_to_video]
frameworks: [pytorch, cog]
cog:
  enabled: true
description: Stable Video Diffusion with Cog (non-commercial license, 24GB VRAM)
notes: |
  This example uses Cog for containerization instead of Docker directly.

  VRAM Requirements:
    - Default decoding_t=1: Works on 23GB GPUs (e.g., A10), ~20GB peak VRAM
    - decoding_t=14: Fastest but requires 24GB+ VRAM
    - Adjust decoding_t based on your GPU memory

  Usage with CVL:
    cvl run svd-cog build
    cvl run svd-cog predict -i input_image=@demo.png
    cvl run svd-cog predict -i input_image=@demo.png -i decoding_t=14  # For 24GB+ GPUs

  Direct Cog usage:
    cog build
    cog predict -i input_image=@demo.png

  Cog manages Docker images internally via cog.yaml configuration.
verification:
  last_verified: 2025-10-26
  last_verification_note: "Fully verified end-to-end on A10 (23GB VRAM). Build succeeds (17.6GB image). Fixed num_steps parameter implementation (passes to sampler.__call__). Fixed seed parameter type (Optional[int]). Inference completes successfully with decoding_t=1 (decode 1 frame at a time) to stay within VRAM limits. Default decoding_t=14 causes CUDA OOM on 23GB GPU. CVL Cog integration working correctly. Model downloads 19GB weights on first run."
