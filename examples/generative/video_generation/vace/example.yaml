name: vace
capability: generative/video_generation
modalities:
- vision
datasets: []
stability: beta
resources:
  gpu: 1
  vram_gb: 24
  disk_gb: 50
  downloads:
    - url: "hf://Wan-AI/Wan2.1-VACE-1.3B/diffusion_pytorch_model.safetensors"
      dest: "models/Wan2.1-VACE-1.3B/diffusion_pytorch_model.safetensors"
    - url: "hf://Wan-AI/Wan2.1-VACE-1.3B/models_t5_umt5-xxl-enc-bf16.pth"
      dest: "models/Wan2.1-VACE-1.3B/models_t5_umt5-xxl-enc-bf16.pth"
    - url: "hf://Wan-AI/Wan2.1-VACE-1.3B/Wan2.1_VAE.pth"
      dest: "models/Wan2.1-VACE-1.3B/Wan2.1_VAE.pth"
    - url: "hf://Wan-AI/Wan2.1-VACE-1.3B/config.json"
      dest: "models/Wan2.1-VACE-1.3B/config.json"
presets:
  build:
    script: build.sh
    description: Build the Docker image
  predict:
    script: predict.sh
    description: Run predict
tags:
- vace
- video-animation
- pytorch
tasks:
- video_generation
frameworks:
- pytorch
description: VACE (Video Animation Control Extension) for video generation
verification:
  last_verified: 2025-10-26
  last_verification_note: "Fixed predict.sh to call vace/vace_pipeline.py. Upgraded Dockerfile base image from pytorch:2.1.2-cuda11.8-cudnn8-devel to pytorch:2.4.0-cuda12.1-cudnn9-devel to resolve GLIBC 2.32+ requirement for flash_attn. Build successful (30.5GB image). GLIBC/flash_attn import error resolved. Preprocessing pipeline works (tested frameref task). Models pre-downloaded (18GB). Script supports --base {ltx,wan}, --sample_steps, and --num_inference_steps. Remaining upstream bugs in VACE code prevent full end-to-end inference (tokenizer path config, PlainImageAnnotator device param). Tested on NVIDIA A10 (24GB VRAM)."
