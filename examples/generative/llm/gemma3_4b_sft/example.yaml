name: gemma3-4b-sft
capability: generative/llm
modalities:
  - text
datasets:
  - mlabonne/FineTome-100k
stability: stable
resources:
  gpu: 1
  vram_gb: 8
  disk_gb: 15
image: cvlization/gemma3-4b-sft:latest
presets:
  build:
    script: build.sh
    description: Build the Docker image
  train:
    script: train.sh
    description: Fine-tune Gemma-3 4B with SFT
  test:
    script: test.sh
    description: Run smoke test (30 steps, 1000 samples)
tags:
  - unsloth
  - gemma
  - gemma-3
  - fine-tuning
  - lora
  - sft
  - pytorch
  - 4bit
tasks:
  - text_generation
  - instruction_following
frameworks:
  - pytorch
  - unsloth
  - transformers
description: Fine-tune Gemma-3 4B with Unsloth for 2x faster training. Uses LoRA/PEFT for efficient fine-tuning with train-on-responses-only masking.
verification:
  last_verified: "2025-11-21"
  last_verification_note: "Fully verified. Docker builds and smoke test passes (30 steps, 1000 samples, 4m 12s, 4.4GB VRAM). Requires build-essential for bitsandbytes/triton compilation. Training completes successfully with model checkpointing."
