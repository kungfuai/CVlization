# @package _global_

defaults:
  - override /data: text8
  - override /model: text8_semicat
  - override /trainer: default

seed: 12345

trainer:
  min_epochs: 100
  max_epochs: 500

tags: ["semicat", "text8"]

model:
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 1e-4
    weight_decay: 0.01
  net:
    length: ${data.k}

data:
  batch_size: 128  # to fit on 20GB

logger:
  wandb:
    group: semicat_sd_text8
    name: semicat-sd-text8-${seed}
    tags: ["semicat", "text8"]
