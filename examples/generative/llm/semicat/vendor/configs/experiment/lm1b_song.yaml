# @package _global_

defaults:
  - override /data: lm1b
  - override /model: lm1b_song
  - override /trainer: default

seed: 12345

trainer:
  min_epochs: 100
  max_epochs: 500
  precision: bf16-true

tags: ["semicat", "lm1b", "song"]

model:
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 1e-4
    weight_decay: 0.0
  net:
    channel_mult:
      - 1
      - 2
      - 2
      - 2
    attn_resolutions:
      - 128
    model_channels: 256
  sd_prop: 0.0

data:
  batch_size: 64

logger:
  wandb:
    group: song_lg_lm1b
    name: ${logger.wandb.group}-${seed}
    tags: ["semicat", "lm1b", "song"]
