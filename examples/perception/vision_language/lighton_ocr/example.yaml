name: lighton-ocr
capability: perception/vision_language
modalities:
  - vision
  - text
stability: experimental
resources:
  gpu: 1
  vram_gb: 16
  disk_gb: 25
image: lighton-ocr
presets:
  build:
    script: build.sh
    description: Build the LightOnOCR vLLM client/server image
  serve:
    script: serve.sh
    description: Launch vLLM OpenAI-compatible server
  predict:
    script: predict.sh
    description: Run local vLLM inference (defaults to sample.jpg)
  test:
    script: test.sh
    description: Smoke-test OCR against sample.jpg (local inference)
tags:
  - ocr
  - document-understanding
  - vllm
  - huggingface
  - pytorch
tasks:
  - ocr
  - document_understanding
frameworks:
  - pytorch
  - vllm
description: Dockerized vLLM server + client for LightOnOCR-1B-1025 (OpenAI-compatible).
verification:
  last_verified: 2025-12-30
  last_verification_note: "Verified build with PyTorch 2.9.1 CUDA 12.8 + vLLM 0.11.2 (pre-built wheel). Inference ~66s (includes 28s JIT compile warmup). Model: lightonai/LightOnOCR-1B-1025, cached to HF hub. Peak VRAM ~12GB KV cache + 1.9GB model. Use --gpu-memory-utilization 0.7 on A10 24GB."
