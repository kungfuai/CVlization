name: moondream2
capability: perception/vision_language
modalities: [vision, text]
datasets: [custom]
stability: stable
resources:
  gpu: 1
  vram_gb: 6
  disk_gb: 5

# Docker image name for this example
image: moondream2

presets:
  build:
    script: build.sh
    description: Build the Docker image
  predict:
    script: predict.sh
    command: python3 predict.py
    description: Run OCR inference on an image
    path_args:
      - flag: "--image"
        type: file
      - flag: "--output"
        type: file
  batch_predict:
    script: batch_predict.py
    description: Batch inference from JSONL
    path_args:
      - flag: "--batch-input"
        type: file
      - flag: "--output-dir"
        type: dir

tags: [moondream, vlm, ocr, vqa, captioning, pytorch]
tasks: [ocr, image_captioning, visual_question_answering]
frameworks: [pytorch]
description: Compact 1.93B vision-language model for OCR, captioning, and visual QA
