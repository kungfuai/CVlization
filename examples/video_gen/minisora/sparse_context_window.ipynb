{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32768, 1)\n"
     ]
    }
   ],
   "source": [
    "# data = np.zeros((2, 8 * 64 * 64)) # 8, 64, 64))\n",
    "data = np.zeros((2, 8, 64, 64))\n",
    "meshgrid_args = [np.arange(s) for s in data.shape[1:]]\n",
    "positions = np.array(\n",
    "    np.meshgrid(\n",
    "        *meshgrid_args,\n",
    "        indexing=\"ij\"\n",
    "    ),\n",
    ")\n",
    "# move the first dimension to the end\n",
    "orig_shape = tuple(range(len(positions.shape)))\n",
    "transposed_shape = orig_shape[1:] + (orig_shape[0],)\n",
    "positions = positions.transpose(*transposed_shape)\n",
    "print(positions.shape)\n",
    "# print(positions[0, 0, 0])\n",
    "# print(positions[2, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32768, 1)\n",
      "[0]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "positions_flat = positions.reshape(-1, positions.shape[-1])\n",
    "print(positions_flat.shape)\n",
    "print(positions_flat[0])\n",
    "print(positions_flat[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9291 9290 9289 9054 6573 4090 6503 9098 5374 5279 7018 5764 5528 7146\n",
      " 3347 3649 4026 9217 4171 7626 8966 6710 7853 6517 4853 4597 7417 6524\n",
      " 3241 6474 8075 3539 7286 6941 6353 6738 4909 6575 7993 5243 3239 9125\n",
      " 5163 4379 9115 8463 7624 7566 4414 3456 9253 7436 7729 4214 9181 4872\n",
      " 8898 7778 3694 4640 8261 6046 8151 4741 9094 3805 6754 5339 7021 8266\n",
      " 5748 7790 4501 8842 8024 6714 7240 5550 4700 4610 4205 4626 7468 8690\n",
      " 5934 5888 9074 6511 4532 8968 8493 6942 5418 7557 5557 8320 6214 5604\n",
      " 8163 8177 6545 6352 3458 7701 9099 6306 9069 8073 3982 8913 4964 9162\n",
      " 3963 3232 5520 3976 5146 7838 9268 8974 6623 5684 6610 6284 8779 4833\n",
      " 8883 8585]\n",
      "target pos: [9291]\n",
      "nearest neighbor: [9290]\n",
      "nearest neighbor: [9289]\n",
      "relative pos: [[1]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "def find_sparse_context_window(target_idx: int, positions, block_size, sparse_block_size):\n",
    "    # positions: (N, 3)\n",
    "    # target_idx: (3,)\n",
    "    # block_size: int\n",
    "    # returns: (block_size, 3)\n",
    "    # find the block_size closest points to the target_idx\n",
    "    # using the L2 distance\n",
    "    # look back at most block_size points\n",
    "    start_idx = max(0, target_idx - block_size)\n",
    "    target_position = positions[target_idx]\n",
    "    # print(\"target pos:\", target_position)\n",
    "    distances = np.linalg.norm(positions[start_idx:target_idx] - target_position, axis=1)\n",
    "    distances_exponential = np.exp(-distances)\n",
    "    distances_exponential += np.random.rand(*distances_exponential.shape) * 1e-1\n",
    "    \n",
    "    # print(distances.shape)\n",
    "    # print(\"distances:\", distances_exponential)\n",
    "    sorted_indices = np.argsort(-distances_exponential)\n",
    "    # print(\"sorted indices:\", sorted_indices)\n",
    "    context_token_idx = np.arange(start_idx, target_idx)[sorted_indices[:sparse_block_size]]\n",
    "    relative_pos = target_position - positions[context_token_idx]\n",
    "    return context_token_idx, relative_pos\n",
    "\n",
    "\n",
    "target_idx = 4096 * 2+ 1100 \n",
    "block_size = int(4096 * 1.5)\n",
    "sparse_block_size = 128\n",
    "\n",
    "context_token_idx, relative_pos = find_sparse_context_window(\n",
    "    target_idx,\n",
    "    positions_flat,\n",
    "    block_size,\n",
    "    sparse_block_size,\n",
    ")\n",
    "print(context_token_idx)\n",
    "print(\"target pos:\", positions_flat[target_idx-1])\n",
    "print(\"nearest neighbor:\", positions_flat[context_token_idx[0] - 1])\n",
    "print(\"nearest neighbor:\", positions_flat[context_token_idx[1] - 1])\n",
    "print(\"relative pos:\", relative_pos[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target pos: [ 2 17 12]\n",
      "0.0078125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff612298a90>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the context window\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "target_pos = positions_flat[target_idx]\n",
    "print(\"target pos:\", target_pos)\n",
    "# last 2 dims of target_pos is the x, y coordinate\n",
    "# draw that in a 2D image\n",
    "\n",
    "frame = np.zeros((64, 64), dtype=np.uint8)\n",
    "previous_frame = frame.copy()\n",
    "frame[int(target_pos[1]), int(target_pos[2])] = 100\n",
    "\n",
    "# draw the context window\n",
    "context_positions = positions_flat[context_token_idx]\n",
    "context_positions = context_positions.astype(int)\n",
    "# print(\"context positions:\", context_positions)\n",
    "for pos in context_positions:\n",
    "    # print(f\"pos0={pos[0]}, target_pos0={target_pos[0]}\")\n",
    "    if int(pos[0]) == int(target_pos[0]):\n",
    "        frame[pos[1], pos[2]] = 255\n",
    "        # print(\"context pos:\", pos)\n",
    "    elif int(pos[0]) == int(target_pos[0]) - 1:\n",
    "        previous_frame[pos[1], pos[2]] = 100\n",
    "        \n",
    "\n",
    "print((frame != 0).mean())\n",
    "# do a subplot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(255 - previous_frame, cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(255 - frame, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(context_idx, sparse_block_size, value=-1):\n",
    "    # context_idx: (sparse_block_size,)\n",
    "    # returns: (sparse_block_size,)\n",
    "    # pad the context_idx to the sparse_block_size\n",
    "    padded = np.ones((sparse_block_size,), dtype=np.int64) * value\n",
    "    padded[:len(context_idx)] = context_idx\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/32768 [00:00<00:02, 12247.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_idx: 0 target_pos: [0 0 0]\n",
      "context position [[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "relative pos: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "context tokens: [-1 -1 -1]\n",
      "--------------------------------------------------\n",
      "target_idx: 2 target_pos: [0 0 2]\n",
      "context position [[ 0  0  1]\n",
      " [ 0  0  0]\n",
      " [-1 -1 -1]]\n",
      "relative pos: [[0. 0. 1.]\n",
      " [0. 0. 2.]\n",
      " [0. 0. 0.]]\n",
      "context tokens: [ 1  0 -1]\n",
      "--------------------------------------------------\n",
      "(102, 128, 3)\n",
      "(102, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "block_size = int(4096 * 1.5)\n",
    "sparse_block_size = 128\n",
    "\n",
    "tokens_flat = np.arange(len(positions_flat))\n",
    "tokens_flat_padded = np.concatenate(\n",
    "    [np.ones((1,), dtype=np.int64) * -1,\n",
    "    tokens_flat],\n",
    "    axis=0,\n",
    ")\n",
    "positions_flat_padded = np.concatenate(\n",
    "    [np.ones((1, 3), dtype=np.int64) * -1,\n",
    "    positions_flat],\n",
    "    axis=0,\n",
    ")\n",
    "# print(positions_flat_padded)\n",
    "\n",
    "\n",
    "relative_pos_lut = []\n",
    "context_token_idx_lut = []\n",
    "for target_idx in tqdm(range(len(positions_flat))):\n",
    "    context_token_idx, relative_pos = find_sparse_context_window(\n",
    "        target_idx,\n",
    "        positions_flat,\n",
    "        block_size,\n",
    "        sparse_block_size,\n",
    "    )\n",
    "    relative_pos_padded = np.concatenate(\n",
    "        [relative_pos, np.zeros((sparse_block_size - len(relative_pos), 3))],\n",
    "        axis=0,\n",
    "    )\n",
    "    # This assumes the positions and tokens will be inserted with a start token\n",
    "    context_token_idx_padded = pad_seq(context_token_idx, sparse_block_size) + 1\n",
    "    if target_idx in [0, 2]:\n",
    "        print(\"target_idx:\", target_idx, \"target_pos:\", positions_flat[target_idx])\n",
    "        # print(\"context token idx padded:\", context_token_idx_padded)\n",
    "        print(\"context position\", positions_flat_padded[context_token_idx_padded[0:3]])\n",
    "        print(\"relative pos:\", relative_pos_padded[:3])\n",
    "        print(\"context tokens:\", tokens_flat_padded[context_token_idx_padded[0:3]])\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    relative_pos_lut.append(relative_pos_padded)\n",
    "    context_token_idx_lut.append(context_token_idx_padded)\n",
    "\n",
    "    if target_idx > 100:\n",
    "        break\n",
    "\n",
    "relative_pos_lut = np.stack(relative_pos_lut, axis=0)\n",
    "context_token_idx_lut = np.stack(context_token_idx_lut, axis=0)\n",
    "print(relative_pos_lut.shape)\n",
    "print(context_token_idx_lut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1])\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.concatenate([torch.tensor([0]), torch.tensor([1])])\n",
    "print(x)\n",
    "idx = np.zeros((1,)).astype(int)\n",
    "print(idx)\n",
    "x[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
